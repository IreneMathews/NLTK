{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Antonyms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5saPenJ4U8wY"
      },
      "source": [
        "# Finding Antonyms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS5pPcuKsi4A"
      },
      "source": [
        "## Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYSmAKcEsUEx",
        "outputId": "a387094e-cdd0-45fb-fd30-182b82972734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import wordnet as wn \n",
        "import regex as re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkVrtlCrswb0"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K8O8pyqxcZm"
      },
      "source": [
        "### declaring text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIwKEPUbvTQu"
      },
      "source": [
        "text = \"A man walked around and found peace\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtfAqMsQxgCB"
      },
      "source": [
        "### remove punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIF-pJSzssW1"
      },
      "source": [
        "text1 = re.sub(\"[./!?,]\", \" \", text) # removing the given punctuations\n",
        "tagged_sentence = nltk.tag.pos_tag(text1.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaXCty9Xxm_K"
      },
      "source": [
        "### removing nouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGHLHHRwwAr",
        "outputId": "b7fabd18-501a-46b7-e8df-791f1c29d500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS'] \n",
        "new_text= \" \".join(edited_sentence) \n",
        "print(new_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man walked around and found peace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fzzfyznxo5i"
      },
      "source": [
        "### removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8-iugGlwZ_7",
        "outputId": "b815f5d6-48eb-4977-9ee0-68703ed560a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_tokens = word_tokenize(new_text) \n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]  \n",
        "print(tokens_without_sw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'walked', 'around', 'found', 'peace']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU2RlcwPxqVq"
      },
      "source": [
        "### finding word by word antonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZWMWp8Nt0TN",
        "outputId": "63c5c177-0e10-4c6f-862d-ac88b06c1640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "ant={}\n",
        "for i in tokens_without_sw:\n",
        "  ant[i] =[]\n",
        "  for synset in wordnet.synsets(i):\n",
        "    for lemma in synset.lemmas():\n",
        "      if lemma.antonyms():\n",
        "        ant[i].append(lemma.antonyms()[0].name())\n",
        "  if(len(ant[i])!=0):\n",
        "    print('Antonyms of '+i+ '  is  :'  + str(ant[i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antonyms of walked  is  :['ride']\n",
            "Antonyms of found  is  :['abolish', 'lose', 'lost']\n",
            "Antonyms of peace  is  :['war']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cihns7ynw64m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}