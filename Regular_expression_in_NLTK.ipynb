{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regular expression in NLTK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjbi8ReQFiYi"
      },
      "source": [
        "# Regular expression in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd46NXaumjl",
        "outputId": "c5eba8e4-1b8d-4b8b-f173-ec76b963f22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJPYey3KFhqD",
        "outputId": "8d8fac72-404c-4fc9-fec7-e85fb397a5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"1) import the library for regular expression( using  NLTK)  \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1) import the library for regular expression( using  NLTK)  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZnswPrKFhtx"
      },
      "source": [
        "from nltk.tokenize import word_tokenize,re\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI-JdByFFhyJ",
        "outputId": "29b2f3fe-31af-42a9-a1a6-8f5dbf0cf2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"2)Use any four methods of Regular Expressions and execute the same (Example: re.match(),re.search()\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2)Use any four methods of Regular Expressions and execute the same (Example: re.match(),re.search()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43l2ZOAjFh1Y",
        "outputId": "67e14709-ae4a-4b90-b4aa-126c0a4834d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.corpus import brown\n",
        "file=brown.words()\n",
        "file\n",
        "s=\" \"\n",
        "# combined brown word file\n",
        "s = s.join(file) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40b9113e7346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# combined brown word file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCxFU4-IhKU",
        "outputId": "12e2cbda-38ac-4bcb-fc20-e183a59603bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# searching all the words starting with ab\n",
        "newarray=[]\n",
        "for i in range(0,len(file)):\n",
        "  if re.search(\"^(ab)\", file[i]):\n",
        "    newarray.append(file[i])\n",
        "\n",
        "set(newarray)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ab',\n",
              " 'aback',\n",
              " 'abandon',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abandonment',\n",
              " 'abaringe',\n",
              " 'abasement',\n",
              " 'abated',\n",
              " 'abberations',\n",
              " 'abbey',\n",
              " 'abbot',\n",
              " 'abbreviated',\n",
              " 'abbreviation',\n",
              " 'abbreviations',\n",
              " 'abdomen',\n",
              " 'abdominal',\n",
              " 'abdominis',\n",
              " 'abduction',\n",
              " 'abed',\n",
              " 'aber',\n",
              " 'aberrant',\n",
              " 'aberration',\n",
              " 'aberrations',\n",
              " 'abetted',\n",
              " 'abeyance',\n",
              " 'abhorred',\n",
              " 'abhorrent',\n",
              " 'abide',\n",
              " 'abides',\n",
              " 'abiding',\n",
              " 'abilities',\n",
              " 'ability',\n",
              " 'abject',\n",
              " 'abjection',\n",
              " 'abjectly',\n",
              " 'ablated',\n",
              " 'ablation',\n",
              " 'ablaze',\n",
              " 'able',\n",
              " 'abler',\n",
              " 'ably',\n",
              " 'abnormal',\n",
              " 'abnormalities',\n",
              " 'abnormally',\n",
              " 'aboard',\n",
              " 'abode',\n",
              " 'abolish',\n",
              " 'abolished',\n",
              " 'abolition',\n",
              " 'abolitionist',\n",
              " 'abolitionists',\n",
              " 'aboriginal',\n",
              " 'aborigine',\n",
              " 'aborigines',\n",
              " 'abortion',\n",
              " 'abortions',\n",
              " 'abortive',\n",
              " 'abound',\n",
              " 'abounded',\n",
              " 'abounding',\n",
              " 'abounds',\n",
              " 'about',\n",
              " 'about-faced',\n",
              " 'above',\n",
              " 'above-ground',\n",
              " 'above-mentioned',\n",
              " 'above-noted',\n",
              " 'above-water',\n",
              " 'aboveground',\n",
              " 'abrasion-resistant',\n",
              " 'abreaction',\n",
              " 'abreast',\n",
              " 'abridged',\n",
              " 'abridgment',\n",
              " 'abroad',\n",
              " 'abroade',\n",
              " 'abrogated',\n",
              " 'abrupt',\n",
              " 'abruptly',\n",
              " 'abruptness',\n",
              " 'abscesses',\n",
              " 'abscissa',\n",
              " 'absence',\n",
              " 'absences',\n",
              " 'absent',\n",
              " 'absent-minded',\n",
              " 'absent-mindedly',\n",
              " 'absented',\n",
              " 'absentee',\n",
              " 'absenteeism',\n",
              " 'absentia',\n",
              " 'absently',\n",
              " 'absentmindedly',\n",
              " 'absinthe',\n",
              " 'absolute',\n",
              " 'absolutely',\n",
              " 'absoluteness',\n",
              " 'absolutes',\n",
              " 'absolution',\n",
              " 'absorb',\n",
              " 'absorbed',\n",
              " 'absorbency',\n",
              " 'absorber',\n",
              " 'absorbing',\n",
              " 'absorbs',\n",
              " 'absorption',\n",
              " 'absorptions',\n",
              " 'absorptive',\n",
              " 'abstain',\n",
              " 'abstaining',\n",
              " 'abstention',\n",
              " 'abstinence',\n",
              " 'abstract',\n",
              " 'abstracted',\n",
              " 'abstractedness',\n",
              " 'abstracting',\n",
              " 'abstraction',\n",
              " 'abstractionism',\n",
              " 'abstractionists',\n",
              " 'abstractions',\n",
              " 'abstractive',\n",
              " 'abstractly',\n",
              " 'abstractors',\n",
              " 'abstracts',\n",
              " 'abstrusenesses',\n",
              " 'absurd',\n",
              " 'absurdities',\n",
              " 'absurdity',\n",
              " 'absurdly',\n",
              " 'abundance',\n",
              " 'abundant',\n",
              " 'abundantly',\n",
              " 'abuse',\n",
              " 'abused',\n",
              " 'abuses',\n",
              " 'abusive',\n",
              " 'abutments',\n",
              " 'abysmal',\n",
              " 'abyss'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaYLnc47YMmk",
        "outputId": "e9542266-cc03-4da1-ad95-10dfa02d928c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(re.findall(\"the\", s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3_NJyTRajWg",
        "outputId": "0c965bbc-66d5-40e7-fcdd-f5f50068b161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Replace every white-space character with the number 9:\n",
        "x = re.sub(\"\\s\", \"9\", s)\n",
        "print(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF2_R4XhbAek",
        "outputId": "72eddba5-6e71-4568-9fdf-f6c1ce801cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# splitting the text with respect to the 9\n",
        "re.split(\"9\", x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of',\n",
              " \"Atlanta's\",\n",
              " 'recent',\n",
              " 'primary',\n",
              " 'election',\n",
              " 'produced',\n",
              " '``',\n",
              " 'no',\n",
              " 'evidence',\n",
              " \"''\",\n",
              " 'that',\n",
              " 'any',\n",
              " 'irregularities',\n",
              " 'took',\n",
              " 'place',\n",
              " '.',\n",
              " 'The',\n",
              " 'jury',\n",
              " 'further',\n",
              " 'said',\n",
              " 'in',\n",
              " 'term-end',\n",
              " 'presentments',\n",
              " 'that',\n",
              " 'the',\n",
              " 'City',\n",
              " 'Executive',\n",
              " 'Committee',\n",
              " ',',\n",
              " 'which',\n",
              " 'had',\n",
              " 'over-all',\n",
              " 'charge',\n",
              " 'of',\n",
              " 'the',\n",
              " 'election',\n",
              " ',',\n",
              " '``',\n",
              " 'deserves',\n",
              " 'the',\n",
              " 'praise',\n",
              " 'and',\n",
              " 'thanks',\n",
              " 'of',\n",
              " 'the',\n",
              " 'City',\n",
              " 'of',\n",
              " 'Atlanta',\n",
              " \"''\",\n",
              " 'for',\n",
              " 'the',\n",
              " 'manner',\n",
              " 'in',\n",
              " 'which',\n",
              " 'the',\n",
              " 'election',\n",
              " 'was',\n",
              " 'conducted',\n",
              " '.',\n",
              " 'The',\n",
              " 'September-October',\n",
              " 'term',\n",
              " 'jury',\n",
              " 'had',\n",
              " 'been',\n",
              " 'charged',\n",
              " 'by',\n",
              " 'Fulton',\n",
              " 'Superior',\n",
              " 'Court',\n",
              " 'Judge',\n",
              " 'Durwood',\n",
              " 'Pye',\n",
              " 'to',\n",
              " 'investigate',\n",
              " 'reports',\n",
              " 'of',\n",
              " 'possible',\n",
              " '``',\n",
              " 'irregularities',\n",
              " \"''\",\n",
              " 'in',\n",
              " 'the',\n",
              " 'hard-fought',\n",
              " 'primary',\n",
              " 'which',\n",
              " 'was',\n",
              " 'won',\n",
              " 'by',\n",
              " 'Mayor-nominate',\n",
              " 'Ivan',\n",
              " 'Allen',\n",
              " 'Jr.',\n",
              " '.',\n",
              " '``',\n",
              " 'Only',\n",
              " 'a',\n",
              " 'relative',\n",
              " 'handful',\n",
              " 'of',\n",
              " 'such',\n",
              " 'reports',\n",
              " 'was',\n",
              " 'received',\n",
              " \"''\",\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'said',\n",
              " ',',\n",
              " '``',\n",
              " 'considering',\n",
              " 'the',\n",
              " 'widespread',\n",
              " 'interest',\n",
              " 'in',\n",
              " 'the',\n",
              " 'election',\n",
              " ',',\n",
              " 'the',\n",
              " 'number',\n",
              " 'of',\n",
              " 'voters',\n",
              " 'and',\n",
              " 'the',\n",
              " 'size',\n",
              " 'of',\n",
              " 'this',\n",
              " 'city',\n",
              " \"''\",\n",
              " '.',\n",
              " 'The',\n",
              " 'jury',\n",
              " 'said',\n",
              " 'it',\n",
              " 'did',\n",
              " 'find',\n",
              " 'that',\n",
              " 'many',\n",
              " 'of',\n",
              " \"Georgia's\",\n",
              " 'registration',\n",
              " 'and',\n",
              " 'election',\n",
              " 'laws',\n",
              " '``',\n",
              " 'are',\n",
              " 'outmoded',\n",
              " 'or',\n",
              " 'inadequate',\n",
              " 'and',\n",
              " 'often',\n",
              " 'ambiguous',\n",
              " \"''\",\n",
              " '.',\n",
              " 'It',\n",
              " 'recommended',\n",
              " 'that',\n",
              " 'Fulton',\n",
              " 'legislators',\n",
              " 'act',\n",
              " '``',\n",
              " 'to',\n",
              " 'have',\n",
              " 'these',\n",
              " 'laws',\n",
              " 'studied',\n",
              " 'and',\n",
              " 'revised',\n",
              " 'to',\n",
              " 'the',\n",
              " 'end',\n",
              " 'of',\n",
              " 'modernizing',\n",
              " 'and',\n",
              " 'improving',\n",
              " 'them',\n",
              " \"''\",\n",
              " '.',\n",
              " 'The',\n",
              " 'grand',\n",
              " 'jury',\n",
              " 'commented',\n",
              " 'on',\n",
              " 'a',\n",
              " 'number',\n",
              " 'of',\n",
              " 'other',\n",
              " 'topics',\n",
              " ',',\n",
              " 'among',\n",
              " 'them',\n",
              " 'the',\n",
              " 'Atlanta',\n",
              " 'and',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'purchasing',\n",
              " 'departments',\n",
              " 'which',\n",
              " 'it',\n",
              " 'said',\n",
              " '``',\n",
              " 'are',\n",
              " 'well',\n",
              " 'operated',\n",
              " 'and',\n",
              " 'follow',\n",
              " 'generally',\n",
              " 'accepted',\n",
              " 'practices',\n",
              " 'which',\n",
              " 'inure',\n",
              " 'to',\n",
              " 'the',\n",
              " 'best',\n",
              " 'interest',\n",
              " 'of',\n",
              " 'both',\n",
              " 'governments',\n",
              " \"''\",\n",
              " '.',\n",
              " 'Merger',\n",
              " 'proposed',\n",
              " 'However',\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'said',\n",
              " 'it',\n",
              " 'believes',\n",
              " '``',\n",
              " 'these',\n",
              " 'two',\n",
              " 'offices',\n",
              " 'should',\n",
              " 'be',\n",
              " 'combined',\n",
              " 'to',\n",
              " 'achieve',\n",
              " 'greater',\n",
              " 'efficiency',\n",
              " 'and',\n",
              " 'reduce',\n",
              " 'the',\n",
              " 'cost',\n",
              " 'of',\n",
              " 'administration',\n",
              " \"''\",\n",
              " '.',\n",
              " 'The',\n",
              " 'City',\n",
              " 'Purchasing',\n",
              " 'Department',\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'said',\n",
              " ',',\n",
              " '``',\n",
              " 'is',\n",
              " 'lacking',\n",
              " 'in',\n",
              " 'experienced',\n",
              " 'clerical',\n",
              " 'personnel',\n",
              " 'as',\n",
              " 'a',\n",
              " 'result',\n",
              " 'of',\n",
              " 'city',\n",
              " 'personnel',\n",
              " 'policies',\n",
              " \"''\",\n",
              " '.',\n",
              " 'It',\n",
              " 'urged',\n",
              " 'that',\n",
              " 'the',\n",
              " 'city',\n",
              " '``',\n",
              " 'take',\n",
              " 'steps',\n",
              " 'to',\n",
              " 'remedy',\n",
              " \"''\",\n",
              " 'this',\n",
              " 'problem',\n",
              " '.',\n",
              " 'Implementation',\n",
              " 'of',\n",
              " \"Georgia's\",\n",
              " 'automobile',\n",
              " 'title',\n",
              " 'law',\n",
              " 'was',\n",
              " 'also',\n",
              " 'recommended',\n",
              " 'by',\n",
              " 'the',\n",
              " 'outgoing',\n",
              " 'jury',\n",
              " '.',\n",
              " 'It',\n",
              " 'urged',\n",
              " 'that',\n",
              " 'the',\n",
              " 'next',\n",
              " 'Legislature',\n",
              " '``',\n",
              " 'provide',\n",
              " 'enabling',\n",
              " 'funds',\n",
              " 'and',\n",
              " 're-set',\n",
              " 'the',\n",
              " 'effective',\n",
              " 'date',\n",
              " 'so',\n",
              " 'that',\n",
              " 'an',\n",
              " 'orderly',\n",
              " 'implementation',\n",
              " 'of',\n",
              " 'the',\n",
              " 'law',\n",
              " 'may',\n",
              " 'be',\n",
              " 'effected',\n",
              " \"''\",\n",
              " '.',\n",
              " 'The',\n",
              " 'grand',\n",
              " 'jury',\n",
              " 'took',\n",
              " 'a',\n",
              " 'swipe',\n",
              " 'at',\n",
              " 'the',\n",
              " 'State',\n",
              " 'Welfare',\n",
              " \"Department's\",\n",
              " 'handling',\n",
              " 'of',\n",
              " 'federal',\n",
              " 'funds',\n",
              " 'granted',\n",
              " 'for',\n",
              " 'child',\n",
              " 'welfare',\n",
              " 'services',\n",
              " 'in',\n",
              " 'foster',\n",
              " 'homes',\n",
              " '.',\n",
              " '``',\n",
              " 'This',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'major',\n",
              " 'items',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'general',\n",
              " 'assistance',\n",
              " 'program',\n",
              " \"''\",\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'said',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'State',\n",
              " 'Welfare',\n",
              " 'Department',\n",
              " '``',\n",
              " 'has',\n",
              " 'seen',\n",
              " 'fit',\n",
              " 'to',\n",
              " 'distribute',\n",
              " 'these',\n",
              " 'funds',\n",
              " 'through',\n",
              " 'the',\n",
              " 'welfare',\n",
              " 'departments',\n",
              " 'of',\n",
              " 'all',\n",
              " 'the',\n",
              " 'counties',\n",
              " 'in',\n",
              " 'the',\n",
              " 'state',\n",
              " 'with',\n",
              " 'the',\n",
              " 'exception',\n",
              " 'of',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " ',',\n",
              " 'which',\n",
              " 'receives',\n",
              " 'none',\n",
              " 'of',\n",
              " 'this',\n",
              " 'money',\n",
              " '.',\n",
              " 'The',\n",
              " 'jurors',\n",
              " 'said',\n",
              " 'they',\n",
              " 'realize',\n",
              " '``',\n",
              " 'a',\n",
              " 'proportionate',\n",
              " 'distribution',\n",
              " 'of',\n",
              " 'these',\n",
              " 'funds',\n",
              " 'might',\n",
              " 'disable',\n",
              " 'this',\n",
              " 'program',\n",
              " 'in',\n",
              " 'our',\n",
              " 'less',\n",
              " 'populous',\n",
              " 'counties',\n",
              " \"''\",\n",
              " '.',\n",
              " 'Nevertheless',\n",
              " ',',\n",
              " '``',\n",
              " 'we',\n",
              " 'feel',\n",
              " 'that',\n",
              " 'in',\n",
              " 'the',\n",
              " 'future',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'should',\n",
              " 'receive',\n",
              " 'some',\n",
              " 'portion',\n",
              " 'of',\n",
              " 'these',\n",
              " 'available',\n",
              " 'funds',\n",
              " \"''\",\n",
              " ',',\n",
              " 'the',\n",
              " 'jurors',\n",
              " 'said',\n",
              " '.',\n",
              " '``',\n",
              " 'Failure',\n",
              " 'to',\n",
              " 'do',\n",
              " 'this',\n",
              " 'will',\n",
              " 'continue',\n",
              " 'to',\n",
              " 'place',\n",
              " 'a',\n",
              " 'disproportionate',\n",
              " 'burden',\n",
              " \"''\",\n",
              " 'on',\n",
              " 'Fulton',\n",
              " 'taxpayers',\n",
              " '.',\n",
              " 'The',\n",
              " 'jury',\n",
              " 'also',\n",
              " 'commented',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Fulton',\n",
              " \"ordinary's\",\n",
              " 'court',\n",
              " 'which',\n",
              " 'has',\n",
              " 'been',\n",
              " 'under',\n",
              " 'fire',\n",
              " 'for',\n",
              " 'its',\n",
              " 'practices',\n",
              " 'in',\n",
              " 'the',\n",
              " 'appointment',\n",
              " 'of',\n",
              " 'appraisers',\n",
              " ',',\n",
              " 'guardians',\n",
              " 'and',\n",
              " 'administrators',\n",
              " 'and',\n",
              " 'the',\n",
              " 'awarding',\n",
              " 'of',\n",
              " 'fees',\n",
              " 'and',\n",
              " 'compensation',\n",
              " '.',\n",
              " 'Wards',\n",
              " 'protected',\n",
              " 'The',\n",
              " 'jury',\n",
              " 'said',\n",
              " 'it',\n",
              " 'found',\n",
              " 'the',\n",
              " 'court',\n",
              " '``',\n",
              " 'has',\n",
              " 'incorporated',\n",
              " 'into',\n",
              " 'its',\n",
              " 'operating',\n",
              " 'procedures',\n",
              " 'the',\n",
              " 'recommendations',\n",
              " \"''\",\n",
              " 'of',\n",
              " 'two',\n",
              " 'previous',\n",
              " 'grand',\n",
              " 'juries',\n",
              " ',',\n",
              " 'the',\n",
              " 'Atlanta',\n",
              " 'Bar',\n",
              " 'Association',\n",
              " 'and',\n",
              " 'an',\n",
              " 'interim',\n",
              " 'citizens',\n",
              " 'committee',\n",
              " '.',\n",
              " '``',\n",
              " 'These',\n",
              " 'actions',\n",
              " 'should',\n",
              " 'serve',\n",
              " 'to',\n",
              " 'protect',\n",
              " 'in',\n",
              " 'fact',\n",
              " 'and',\n",
              " 'in',\n",
              " 'effect',\n",
              " 'the',\n",
              " \"court's\",\n",
              " 'wards',\n",
              " 'from',\n",
              " 'undue',\n",
              " 'costs',\n",
              " 'and',\n",
              " 'its',\n",
              " 'appointed',\n",
              " 'and',\n",
              " 'elected',\n",
              " 'servants',\n",
              " 'from',\n",
              " 'unmeritorious',\n",
              " 'criticisms',\n",
              " \"''\",\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'said',\n",
              " '.',\n",
              " 'Regarding',\n",
              " \"Atlanta's\",\n",
              " 'new',\n",
              " 'multi-million-dollar',\n",
              " 'airport',\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'recommended',\n",
              " '``',\n",
              " 'that',\n",
              " 'when',\n",
              " 'the',\n",
              " 'new',\n",
              " 'management',\n",
              " 'takes',\n",
              " 'charge',\n",
              " 'Jan.',\n",
              " '1',\n",
              " 'the',\n",
              " 'airport',\n",
              " 'be',\n",
              " 'operated',\n",
              " 'in',\n",
              " 'a',\n",
              " 'manner',\n",
              " 'that',\n",
              " 'will',\n",
              " 'eliminate',\n",
              " 'political',\n",
              " 'influences',\n",
              " \"''\",\n",
              " '.',\n",
              " 'The',\n",
              " 'jury',\n",
              " 'did',\n",
              " 'not',\n",
              " 'elaborate',\n",
              " ',',\n",
              " 'but',\n",
              " 'it',\n",
              " 'added',\n",
              " 'that',\n",
              " '``',\n",
              " 'there',\n",
              " 'should',\n",
              " 'be',\n",
              " 'periodic',\n",
              " 'surveillance',\n",
              " 'of',\n",
              " 'the',\n",
              " 'pricing',\n",
              " 'practices',\n",
              " 'of',\n",
              " 'the',\n",
              " 'concessionaires',\n",
              " 'for',\n",
              " 'the',\n",
              " 'purpose',\n",
              " 'of',\n",
              " 'keeping',\n",
              " 'the',\n",
              " 'prices',\n",
              " 'reasonable',\n",
              " \"''\",\n",
              " '.',\n",
              " 'Ask',\n",
              " 'jail',\n",
              " 'deputies',\n",
              " 'On',\n",
              " 'other',\n",
              " 'matters',\n",
              " ',',\n",
              " 'the',\n",
              " 'jury',\n",
              " 'recommended',\n",
              " 'that',\n",
              " ':',\n",
              " '(',\n",
              " '1',\n",
              " ')',\n",
              " 'Four',\n",
              " 'additional',\n",
              " 'deputies',\n",
              " 'be',\n",
              " 'employed',\n",
              " 'at',\n",
              " 'the',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Jail',\n",
              " 'and',\n",
              " '``',\n",
              " 'a',\n",
              " 'doctor',\n",
              " ',',\n",
              " 'medical',\n",
              " 'intern',\n",
              " 'or',\n",
              " 'extern',\n",
              " 'be',\n",
              " 'employed',\n",
              " 'for',\n",
              " 'night',\n",
              " 'and',\n",
              " 'weekend',\n",
              " 'duty',\n",
              " 'at',\n",
              " 'the',\n",
              " 'jail',\n",
              " \"''\",\n",
              " '.',\n",
              " '(',\n",
              " '2',\n",
              " ')',\n",
              " 'Fulton',\n",
              " 'legislators',\n",
              " '``',\n",
              " 'work',\n",
              " 'with',\n",
              " 'city',\n",
              " 'officials',\n",
              " 'to',\n",
              " 'pass',\n",
              " 'enabling',\n",
              " 'legislation',\n",
              " 'that',\n",
              " 'will',\n",
              " 'permit',\n",
              " 'the',\n",
              " 'establishment',\n",
              " 'of',\n",
              " 'a',\n",
              " 'fair',\n",
              " 'and',\n",
              " 'equitable',\n",
              " \"''\",\n",
              " 'pension',\n",
              " 'plan',\n",
              " 'for',\n",
              " 'city',\n",
              " 'employes',\n",
              " '.',\n",
              " 'The',\n",
              " 'jury',\n",
              " 'praised',\n",
              " 'the',\n",
              " 'administration',\n",
              " 'and',\n",
              " 'operation',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Atlanta',\n",
              " 'Police',\n",
              " 'Department',\n",
              " ',',\n",
              " 'the',\n",
              " 'Fulton',\n",
              " 'Tax',\n",
              " \"Commissioner's\",\n",
              " 'Office',\n",
              " ',',\n",
              " 'the',\n",
              " 'Bellwood',\n",
              " 'and',\n",
              " 'Alpharetta',\n",
              " 'prison',\n",
              " 'farms',\n",
              " ',',\n",
              " 'Grady',\n",
              " 'Hospital',\n",
              " 'and',\n",
              " 'the',\n",
              " 'Fulton',\n",
              " 'Health',\n",
              " 'Department',\n",
              " '.',\n",
              " 'Mayor',\n",
              " 'William',\n",
              " 'B.',\n",
              " 'Hartsfield',\n",
              " 'filed',\n",
              " 'suit',\n",
              " 'for',\n",
              " 'divorce',\n",
              " 'from',\n",
              " 'his',\n",
              " 'wife',\n",
              " ',',\n",
              " 'Pearl',\n",
              " 'Williams',\n",
              " 'Hartsfield',\n",
              " ',',\n",
              " 'in',\n",
              " 'Fulton',\n",
              " 'Superior',\n",
              " 'Court',\n",
              " 'Friday',\n",
              " '.',\n",
              " 'His',\n",
              " 'petition',\n",
              " 'charged',\n",
              " 'mental',\n",
              " 'cruelty',\n",
              " '.',\n",
              " 'The',\n",
              " 'couple',\n",
              " 'was',\n",
              " 'married',\n",
              " 'Aug.',\n",
              " '2',\n",
              " ',',\n",
              " '1',\n",
              " '13',\n",
              " '.',\n",
              " 'They',\n",
              " 'have',\n",
              " 'a',\n",
              " 'son',\n",
              " ',',\n",
              " 'William',\n",
              " 'Berry',\n",
              " 'Jr.',\n",
              " ',',\n",
              " 'and',\n",
              " 'a',\n",
              " 'daughter',\n",
              " ',',\n",
              " 'Mrs.',\n",
              " 'J.',\n",
              " 'M.',\n",
              " 'Cheshire',\n",
              " 'of',\n",
              " 'Griffin',\n",
              " '.',\n",
              " 'Attorneys',\n",
              " 'for',\n",
              " 'the',\n",
              " 'mayor',\n",
              " 'said',\n",
              " 'that',\n",
              " 'an',\n",
              " 'amicable',\n",
              " 'property',\n",
              " 'settlement',\n",
              " 'has',\n",
              " 'been',\n",
              " 'agreed',\n",
              " 'upon',\n",
              " '.',\n",
              " 'The',\n",
              " 'petition',\n",
              " 'listed',\n",
              " 'the',\n",
              " \"mayor's\",\n",
              " 'occupation',\n",
              " 'as',\n",
              " '``',\n",
              " 'attorney',\n",
              " \"''\",\n",
              " 'and',\n",
              " 'his',\n",
              " 'age',\n",
              " 'as',\n",
              " '71',\n",
              " '.',\n",
              " 'It',\n",
              " 'listed',\n",
              " 'his',\n",
              " \"wife's\",\n",
              " 'age',\n",
              " 'as',\n",
              " '74',\n",
              " 'and',\n",
              " 'place',\n",
              " 'of',\n",
              " 'birth',\n",
              " 'as',\n",
              " 'Opelika',\n",
              " ',',\n",
              " 'Ala.',\n",
              " '.',\n",
              " 'The',\n",
              " 'petition',\n",
              " 'said',\n",
              " 'that',\n",
              " 'the',\n",
              " 'couple',\n",
              " 'has',\n",
              " 'not',\n",
              " 'lived',\n",
              " 'together',\n",
              " 'as',\n",
              " 'man',\n",
              " 'and',\n",
              " 'wife',\n",
              " 'for',\n",
              " 'more',\n",
              " 'than',\n",
              " 'a',\n",
              " 'year',\n",
              " '.',\n",
              " 'The',\n",
              " 'Hartsfield',\n",
              " 'home',\n",
              " 'is',\n",
              " 'at',\n",
              " '637',\n",
              " 'E.',\n",
              " 'Pelham',\n",
              " 'Rd.',\n",
              " 'Aj',\n",
              " '.',\n",
              " 'Henry',\n",
              " 'L.',\n",
              " 'Bowden',\n",
              " 'was',\n",
              " 'listed',\n",
              " 'on',\n",
              " 'the',\n",
              " 'petition',\n",
              " 'as',\n",
              " 'the',\n",
              " \"mayor's\",\n",
              " 'attorney',\n",
              " '.',\n",
              " 'Hartsfield',\n",
              " 'has',\n",
              " 'been',\n",
              " 'mayor',\n",
              " 'of',\n",
              " 'Atlanta',\n",
              " ',',\n",
              " 'with',\n",
              " 'exception',\n",
              " 'of',\n",
              " 'one',\n",
              " 'brief',\n",
              " 'interlude',\n",
              " ',',\n",
              " 'since',\n",
              " '1',\n",
              " '37',\n",
              " '.',\n",
              " 'His',\n",
              " 'political',\n",
              " 'career',\n",
              " 'goes',\n",
              " 'back',\n",
              " 'to',\n",
              " 'his',\n",
              " 'election',\n",
              " 'to',\n",
              " 'city',\n",
              " 'council',\n",
              " 'in',\n",
              " '1',\n",
              " '23',\n",
              " '.',\n",
              " 'The',\n",
              " \"mayor's\",\n",
              " 'present',\n",
              " 'term',\n",
              " 'of',\n",
              " 'office',\n",
              " 'expires',\n",
              " 'Jan.',\n",
              " '1',\n",
              " '.',\n",
              " 'He',\n",
              " 'will',\n",
              " 'be',\n",
              " 'succeeded',\n",
              " 'by',\n",
              " 'Ivan',\n",
              " 'Allen',\n",
              " 'Jr.',\n",
              " ',',\n",
              " 'who',\n",
              " 'became',\n",
              " 'a',\n",
              " 'candidate',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Sept.',\n",
              " '13',\n",
              " 'primary',\n",
              " 'after',\n",
              " 'Mayor',\n",
              " 'Hartsfield',\n",
              " 'announced',\n",
              " 'that',\n",
              " 'he',\n",
              " 'would',\n",
              " 'not',\n",
              " 'run',\n",
              " 'for',\n",
              " 'reelection',\n",
              " '.',\n",
              " 'Georgia',\n",
              " 'Republicans',\n",
              " 'are',\n",
              " 'getting',\n",
              " 'strong',\n",
              " 'encouragement',\n",
              " 'to',\n",
              " 'enter',\n",
              " 'a',\n",
              " 'candidate',\n",
              " 'in',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guKHGhpSIhNb",
        "outputId": "3dd3c717-e7be-4172-cdc0-07f4f96e46c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from nltk.corpus import gutenberg, nps_chat\n",
        "# findall\n",
        "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
        "print(moby.findall(r'<a><.*><man>'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a monied man; a nervous man; a dangerous man; a white man; a white\n",
            "man; a white man; a pious man; a queer man; a good man; a mature man;\n",
            "a white man; a Cape man; a great man; a wise man; a wise man; a\n",
            "butterless man; a white man; a fiendish man; a pale man; a furious\n",
            "man; a better man; a certain man; a complete man; a dismasted man; a\n",
            "younger man; a brave man; a brave man; a brave man; a brave man\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmQ3A0xXFh4B",
        "outputId": "27bd8769-af41-44a0-e7ad-06c178c25537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"3)Write a regular expression to find \\na) All the strings that start at the beginning of line with an integer and that end at the end of the line with a word \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3)Write a regular expression to find \n",
            "a) All the strings that start at the beginning of line with an integer and that end at the end of the line with a word \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS73BjNfe95P"
      },
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "text = movie_reviews.words()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQIfFWyu0qLD",
        "outputId": "a64df373-0175-4554-e285-a620f410c748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "count=0\n",
        "for i in text:\n",
        "  x = re.findall(\"^[0-9].+[a-zA-Z]+$\",i)\n",
        "  if x:\n",
        "    count = count+1\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20th\n",
            "90s\n",
            "1990s\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "17th\n",
            "1970s\n",
            "80s\n",
            "1990s\n",
            "1980s\n",
            "1970s\n",
            "13th\n",
            "1900s\n",
            "30ish\n",
            "19th\n",
            "1998s\n",
            "80s\n",
            "90s\n",
            "20th\n",
            "13th\n",
            "70s\n",
            "20th\n",
            "70s\n",
            "1960s\n",
            "18th\n",
            "90s\n",
            "60s\n",
            "80s\n",
            "13th\n",
            "20th\n",
            "80s\n",
            "6th\n",
            "1950s\n",
            "60s\n",
            "1980s\n",
            "70s\n",
            "80s\n",
            "80s\n",
            "90s\n",
            "1950s\n",
            "1990s\n",
            "10b\n",
            "1960s\n",
            "1970s\n",
            "13th\n",
            "50s\n",
            "60s\n",
            "1960s\n",
            "60s\n",
            "50s\n",
            "30s\n",
            "80s\n",
            "11th\n",
            "1970s\n",
            "13th\n",
            "13th\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "1960s\n",
            "1990s\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "20th\n",
            "70ies\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "70s\n",
            "70s\n",
            "1990s\n",
            "70s\n",
            "70s\n",
            "80s\n",
            "80s\n",
            "17th\n",
            "30th\n",
            "18th\n",
            "13th\n",
            "80s\n",
            "00s\n",
            "50s\n",
            "100m\n",
            "100m\n",
            "100m\n",
            "30m\n",
            "70m\n",
            "26th\n",
            "70s\n",
            "50s\n",
            "21st\n",
            "20s\n",
            "8th\n",
            "11th\n",
            "19th\n",
            "8th\n",
            "60s\n",
            "60s\n",
            "500k\n",
            "2am\n",
            "80s\n",
            "70s\n",
            "1hr\n",
            "40mins\n",
            "1960s\n",
            "60s\n",
            "20s\n",
            "50s\n",
            "4th\n",
            "13th\n",
            "15th\n",
            "5th\n",
            "26th\n",
            "80s\n",
            "80s\n",
            "1980s\n",
            "80s\n",
            "80s\n",
            "80s\n",
            "70s\n",
            "1700s\n",
            "90s\n",
            "1980s\n",
            "23rd\n",
            "24th\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "80s\n",
            "1930s\n",
            "20th\n",
            "1950s\n",
            "70s\n",
            "90s\n",
            "70s\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "4th\n",
            "13th\n",
            "57th\n",
            "20th\n",
            "4am\n",
            "1960s\n",
            "8mm\n",
            "60s\n",
            "90s\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "95s\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "2hr\n",
            "1980s\n",
            "1980s\n",
            "80s\n",
            "70s\n",
            "80s\n",
            "70s\n",
            "7th\n",
            "1980s\n",
            "30th\n",
            "30th\n",
            "50s\n",
            "10th\n",
            "17th\n",
            "70s\n",
            "80s\n",
            "1800s\n",
            "8mm\n",
            "90s\n",
            "1970s\n",
            "1970s\n",
            "50th\n",
            "1960s\n",
            "1950s\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "8mm\n",
            "4th\n",
            "90s\n",
            "60s\n",
            "70s\n",
            "18s\n",
            "80s\n",
            "1980s\n",
            "1980s\n",
            "20thcentury\n",
            "20thcentury\n",
            "16mm\n",
            "19th\n",
            "10th\n",
            "1940s\n",
            "90s\n",
            "1990s\n",
            "1970s\n",
            "1960s\n",
            "1970s\n",
            "20th\n",
            "20th\n",
            "20th\n",
            "1980s\n",
            "48th\n",
            "38th\n",
            "747s\n",
            "19th\n",
            "28up\n",
            "60s\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "1990s\n",
            "60s\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "80s\n",
            "13th\n",
            "13th\n",
            "13th\n",
            "4th\n",
            "80s\n",
            "80s\n",
            "80s\n",
            "25th\n",
            "1940s\n",
            "19th\n",
            "90s\n",
            "70s\n",
            "1990s\n",
            "70s\n",
            "9mm\n",
            "1990s\n",
            "500th\n",
            "19th\n",
            "1970s\n",
            "10s\n",
            "1970s\n",
            "1980s\n",
            "1990s\n",
            "4th\n",
            "1980s\n",
            "1970s\n",
            "60s\n",
            "1980s\n",
            "15th\n",
            "1950s\n",
            "31st\n",
            "20th\n",
            "20th\n",
            "25th\n",
            "1980s\n",
            "1980s\n",
            "17th\n",
            "20th\n",
            "80s\n",
            "1600s\n",
            "1800s\n",
            "80s\n",
            "51st\n",
            "90s\n",
            "90s\n",
            "18th\n",
            "17th\n",
            "70s\n",
            "80s\n",
            "19th\n",
            "60s\n",
            "1800s\n",
            "34th\n",
            "34th\n",
            "1990s\n",
            "1950s\n",
            "1960s\n",
            "1970s\n",
            "1990s\n",
            "1990s\n",
            "3po\n",
            "3po\n",
            "60s\n",
            "60s\n",
            "90s\n",
            "3po\n",
            "3po\n",
            "8th\n",
            "36th\n",
            "90s\n",
            "35th\n",
            "1990s\n",
            "13th\n",
            "1960s\n",
            "1950s\n",
            "1960s\n",
            "1930s\n",
            "1960s\n",
            "80s\n",
            "0009f\n",
            "35mm\n",
            "35mm\n",
            "70s\n",
            "90s\n",
            "19th\n",
            "20th\n",
            "80s\n",
            "1970s\n",
            "50s\n",
            "60s\n",
            "1980s\n",
            "4th\n",
            "90s\n",
            "1980s\n",
            "56k\n",
            "19th\n",
            "50s\n",
            "20th\n",
            "50s\n",
            "50s\n",
            "50s\n",
            "26min\n",
            "7th\n",
            "7th\n",
            "14th\n",
            "3rd\n",
            "1990s\n",
            "1970s\n",
            "1970s\n",
            "1970s\n",
            "1st\n",
            "19th\n",
            "1980s\n",
            "20th\n",
            "1980s\n",
            "1970s\n",
            "1960s\n",
            "1970s\n",
            "1980s\n",
            "80s\n",
            "80s\n",
            "1930s\n",
            "1930s\n",
            "1970s\n",
            "1930s\n",
            "20th\n",
            "24th\n",
            "21st\n",
            "21st\n",
            "21st\n",
            "1830s\n",
            "24th\n",
            "150th\n",
            "1980s\n",
            "1950s\n",
            "1960s\n",
            "1970s\n",
            "1960s\n",
            "92t\n",
            "92s\n",
            "92s\n",
            "92s\n",
            "92t\n",
            "92t\n",
            "92re\n",
            "92re\n",
            "92s\n",
            "92s\n",
            "92s\n",
            "92ve\n",
            "92s\n",
            "92ve\n",
            "92s\n",
            "92t\n",
            "92ll\n",
            "92t\n",
            "21st\n",
            "14th\n",
            "90s\n",
            "19th\n",
            "17th\n",
            "19th\n",
            "19th\n",
            "19th\n",
            "90s\n",
            "9mm\n",
            "1950s\n",
            "50s\n",
            "16th\n",
            "90s\n",
            "18th\n",
            "4th\n",
            "80s\n",
            "50s\n",
            "1500s\n",
            "80s\n",
            "80s\n",
            "3rd\n",
            "90s\n",
            "1960s\n",
            "20th\n",
            "37th\n",
            "20th\n",
            "1960s\n",
            "1960s\n",
            "1980s\n",
            "1970s\n",
            "1930s\n",
            "1940s\n",
            "90s\n",
            "21st\n",
            "3rd\n",
            "90s\n",
            "12th\n",
            "70s\n",
            "80s\n",
            "5th\n",
            "1980s\n",
            "13th\n",
            "18th\n",
            "19th\n",
            "60s\n",
            "70s\n",
            "1500s\n",
            "50s\n",
            "13th\n",
            "20th\n",
            "18th\n",
            "19th\n",
            "2nd\n",
            "16mm\n",
            "19th\n",
            "19th\n",
            "90s\n",
            "90s\n",
            "50s\n",
            "90s\n",
            "90s\n",
            "40s\n",
            "90s\n",
            "70s\n",
            "80s\n",
            "80s\n",
            "40s\n",
            "50s\n",
            "40s\n",
            "50s\n",
            "60s\n",
            "80s\n",
            "70s\n",
            "80s\n",
            "70s\n",
            "80s\n",
            "70s\n",
            "70s\n",
            "1970s\n",
            "1980s\n",
            "1990s\n",
            "1970s\n",
            "19th\n",
            "90s\n",
            "80s\n",
            "1st\n",
            "1950s\n",
            "26th\n",
            "70s\n",
            "90s\n",
            "16mm\n",
            "70s\n",
            "21a\n",
            "1950s\n",
            "1960s\n",
            "1950s\n",
            "1960s\n",
            "8mm\n",
            "1970s\n",
            "1980s\n",
            "70s\n",
            "80s\n",
            "1970s\n",
            "1970s\n",
            "1970s\n",
            "50s\n",
            "5th\n",
            "70s\n",
            "1970s\n",
            "1980s\n",
            "70s\n",
            "1970s\n",
            "1980s\n",
            "100m\n",
            "1998s\n",
            "20th\n",
            "1970s\n",
            "1990s\n",
            "1950s\n",
            "80s\n",
            "50s\n",
            "70s\n",
            "90s\n",
            "90s\n",
            "48th\n",
            "48th\n",
            "7th\n",
            "20th\n",
            "60s\n",
            "1990s\n",
            "15th\n",
            "20th\n",
            "1990s\n",
            "20th\n",
            "8mm\n",
            "16mm\n",
            "35mm\n",
            "1970s\n",
            "1970s\n",
            "1960s\n",
            "70s\n",
            "1970s\n",
            "1980s\n",
            "1980s\n",
            "1960s\n",
            "1980s\n",
            "60s\n",
            "1990s\n",
            "20th\n",
            "5th\n",
            "6th\n",
            "80s\n",
            "3rd\n",
            "60s\n",
            "90s\n",
            "80s\n",
            "13th\n",
            "1990s\n",
            "2th\n",
            "70s\n",
            "2th\n",
            "1920s\n",
            "60s\n",
            "60s\n",
            "60s\n",
            "60s\n",
            "20somethings\n",
            "19th\n",
            "17th\n",
            "35mm\n",
            "80s\n",
            "90s\n",
            "80s\n",
            "80s\n",
            "80s\n",
            "80s\n",
            "90s\n",
            "3po\n",
            "1960s\n",
            "1960s\n",
            "70mm\n",
            "70s\n",
            "20th\n",
            "90s\n",
            "50s\n",
            "25th\n",
            "70s\n",
            "70s\n",
            "85but\n",
            "25th\n",
            "1800s\n",
            "90s\n",
            "60s\n",
            "90s\n",
            "60s\n",
            "80s\n",
            "28th\n",
            "16th\n",
            "21st\n",
            "5th\n",
            "1960s\n",
            "1970s\n",
            "19th\n",
            "1970s\n",
            "1970s\n",
            "1960s\n",
            "70s\n",
            "70s\n",
            "70s\n",
            "20th\n",
            "2nd\n",
            "4th\n",
            "1970s\n",
            "20th\n",
            "50s\n",
            "25th\n",
            "65th\n",
            "70mm\n",
            "60s\n",
            "2nd\n",
            "1960s\n",
            "1960s\n",
            "19th\n",
            "18th\n",
            "1940s\n",
            "13th\n",
            "4th\n",
            "90s\n",
            "1940s\n",
            "2nd\n",
            "14th\n",
            "90s\n",
            "1st\n",
            "30th\n",
            "40s\n",
            "90s\n",
            "1960s\n",
            "1990s\n",
            "1990s\n",
            "40s\n",
            "50s\n",
            "70s\n",
            "80s\n",
            "19th\n",
            "14th\n",
            "1960s\n",
            "8mm\n",
            "16mm\n",
            "80s\n",
            "50s\n",
            "60s\n",
            "54th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNNy3dnaFh85",
        "outputId": "4bd03959-16f1-4b41-db1b-ea57ca86e410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"b) The set of all strings with two consecutive repeated words( Example: 'the the' or 'Dumbledore Dumbledore' but not 'the girl' or 'the little girl')\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b) The set of all strings with two consecutive repeated words( Example: 'the the' or 'Dumbledore Dumbledore' but not 'the girl' or 'the little girl')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9qxXD0OFh-5",
        "outputId": "3f4f1cd7-8bf6-46ad-d27e-71094e5b04da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text1 = \"this is the the name in my house.\"\n",
        "x = re.findall(r'\\b([a-zA-Z]+)\\s+\\1\\b',text1)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAUNqhWnvtrm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}